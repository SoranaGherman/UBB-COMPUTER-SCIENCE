{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#model1 = nn.Sequential(OrderedDict([\n",
    "#    ('hidden', nn.\n",
    "#]))\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 2)),\n",
    "    ('sigmoid', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(2, 2)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),\n",
    "    ('sigmoid', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(4, 2)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 8)),\n",
    "    ('sigmoid', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(8, 2)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "# the database contains 0 and 1 as we have to add 2 bits\n",
    "# 3 layers : input layer, hidden layer and output layer\n",
    "# each layer contains 2 neurons\n",
    "# sigmoid function is the used activation function\n",
    "\n",
    "# for model1\n",
    "# input layer has 2 neurons, hidden layer has 2 neurons and output layer has 2 neurons\n",
    "\n",
    "# for model2\n",
    "# input layer has 2 neurons, hidden layer has 4 neurons and output layer has 2 neurons\n",
    "\n",
    "# for model3\n",
    "# input layer has 2 neurons, hidden layer has 8 neurons and output layer has 2 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (output): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_in = torch.tensor( ...\n",
    "\n",
    "# Create a tensor containing all possible 2-bit input combinations\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# data_target = torch.tensor( ...\n",
    "\n",
    "\n",
    "# Create a tensor containing the target output for each input combination\n",
    "data_target = torch.tensor([[0,  0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# criterion = \n",
    "# optimizer = \n",
    "\n",
    "# Define the binary cross-entropy loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define the Adam optimizer with a learning rate of 0.1\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.1)\n",
    "optimizer2 = optim.SGD(model2.parameters(), lr=0.1)\n",
    "optimizer3 = optim.SGD(model3.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1\n",
      "Epoch [100/1000], Loss: 0.4582\n",
      "Epoch [200/1000], Loss: 0.4497\n",
      "Epoch [300/1000], Loss: 0.4416\n",
      "Epoch [400/1000], Loss: 0.4339\n",
      "Epoch [500/1000], Loss: 0.4266\n",
      "Epoch [600/1000], Loss: 0.4198\n",
      "Epoch [700/1000], Loss: 0.4134\n",
      "Epoch [800/1000], Loss: 0.4074\n",
      "Epoch [900/1000], Loss: 0.4017\n",
      "Epoch [1000/1000], Loss: 0.3964\n",
      "\n",
      "\n",
      "MODEL 2\n",
      "Epoch [100/1000], Loss: 0.3591\n",
      "Epoch [200/1000], Loss: 0.3507\n",
      "Epoch [300/1000], Loss: 0.3415\n",
      "Epoch [400/1000], Loss: 0.3313\n",
      "Epoch [500/1000], Loss: 0.3202\n",
      "Epoch [600/1000], Loss: 0.3082\n",
      "Epoch [700/1000], Loss: 0.2954\n",
      "Epoch [800/1000], Loss: 0.2820\n",
      "Epoch [900/1000], Loss: 0.2681\n",
      "Epoch [1000/1000], Loss: 0.2538\n",
      "\n",
      "\n",
      "MODEL 3\n",
      "Epoch [100/1000], Loss: 0.3796\n",
      "Epoch [200/1000], Loss: 0.3756\n",
      "Epoch [300/1000], Loss: 0.3713\n",
      "Epoch [400/1000], Loss: 0.3667\n",
      "Epoch [500/1000], Loss: 0.3616\n",
      "Epoch [600/1000], Loss: 0.3559\n",
      "Epoch [700/1000], Loss: 0.3494\n",
      "Epoch [800/1000], Loss: 0.3421\n",
      "Epoch [900/1000], Loss: 0.3339\n",
      "Epoch [1000/1000], Loss: 0.3250\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "\n",
    "# Train the model for 1000 epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "print('MODEL 1')\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model1(data_in)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, data_target)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "print('\\n')\n",
    "        \n",
    "print('MODEL 2')\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model2(data_in)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, data_target)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "print('\\n')        \n",
    "        \n",
    "print('MODEL 3')\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    output = model3(data_in)\n",
    "    \n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, data_target)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer3.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer3.step()\n",
    "    \n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1's predictions:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.]])\n",
      "Model2's predictions:\n",
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Model3's predictions:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# visualize the resuts\n",
    "\n",
    "output1 = model1(data_in)\n",
    "\n",
    "# Convert the output probabilities to binary predictions\n",
    "predictions = (output1 >= 0.5).float()\n",
    "\n",
    "# Print the model's predictions\n",
    "print(\"Model1's predictions:\")\n",
    "print(predictions)\n",
    "\n",
    "output1 = model2(data_in)\n",
    "\n",
    "# Convert the output probabilities to binary predictions\n",
    "predictions = (output1 >= 0.5).float()\n",
    "\n",
    "# Print the model's predictions\n",
    "print(\"Model2's predictions:\")\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "output1 = model3(data_in)\n",
    "\n",
    "# Convert the output probabilities to binary predictions\n",
    "predictions = (output1 >= 0.5).float()\n",
    "\n",
    "# Print the model's predictions\n",
    "print(\"Model3's predictions:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.00%\n",
      "Accuracy: 100.00%\n",
      "Accuracy: 75.00%\n",
      "\n",
      "\n",
      "Model 2 is the best!\n",
      "\n",
      "\n",
      "hidden.weight tensor([[-2.5194, -2.5022],\n",
      "        [-1.2399, -1.7273],\n",
      "        [-2.9751, -2.6053],\n",
      "        [ 1.3578,  2.0023]])\n",
      "hidden.bias tensor([ 0.7005,  0.1221,  4.1706, -2.1453])\n",
      "output.weight tensor([[-2.7793, -1.8374, -5.6114,  3.9682],\n",
      "        [-2.4704, -1.1525,  2.0726, -0.7463]])\n",
      "output.bias tensor([ 0.4617, -0.2094])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# print model wights\n",
    "\n",
    "accuracies = []\n",
    "models = [model1, model2, model3]\n",
    "for model in models:\n",
    "    model.eval()\n",
    "#with torch.no_grad():\n",
    "    outputs = model(data_in)\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    accuracy = (predicted == data_target).float().mean()\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy.item() * 100))\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "# Select the best-performing model\n",
    "best_model = models[accuracies.index(max(accuracies))]\n",
    "\n",
    "\n",
    "print('Model ' + str(accuracies.index(max(accuracies)) + 1) + ' is the best!')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Display the weights of each layer in the selected model\n",
    "for name, param in best_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
